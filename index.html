<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="icon" type="image/vnd.microsoft.icon" href="/images/favicon.ico">
    <title>Zhuo Zheng - Stanford University</title>
    <script src="lib/jq214/jquery.js"></script>

    <link rel="stylesheet" type="text/css" href="css/bootstrap-simplex.min.css">
    <script src="lib/bts4b2/bootstrap.bundle.min.js"></script>
    <script src="https://kit.fontawesome.com/0cf3363282.js" crossorigin="anonymous"></script>
    <style>
        #bio {
            text-align: center;
            position: relative;
        }

        ul {
            list-style-type: none;
            padding: 0;
        }

        li.link {
            float: left;
            margin-left: 10px;
        }

        .myname {
            color: black;
        }

        .itemtitle {
            color: black;
        }

        .my_highlight {
            color: #0028ff
        }

        .paper_highlight {
            color: #9d190b;
        }

        .checked {
            color: orange;
        }
    </style>
</head>
<body>


<div class="container" style="margin-top: 20px">
    <div class="row">
        <div class="col-md-3">
            <div id="bio">
                <img src="images/me_sea.jpg" class="rounded-circle" style="width:70%;margin-top: 10px;" alt="zhuozheng">
                <div style="margin: 10px;">
                    Zhuo Zheng
                    <br>
                    <a href="https://cs.stanford.edu/">Department of Computer Science</a>
                    <br>
                    <a href="https://www.stanford.edu/">Stanford University</a>
                </div>
            </div>
        </div>
        <div class="col-md-9">
            <p>
                Bio: I am currently a postdoc at Stanford Artificial Intelligence Laboratory (SAIL), Department of Computer
                Science, Stanford University, working with Prof. <a href="https://cs.stanford.edu/~ermon/">Stefano
                Ermon</a>, Prof. <a href="https://earth.stanford.edu/people/david-lobell">David Lobell</a>, and Prof. <a
                    href="https://web.stanford.edu/~mburke/">Marshall Burke</a>.
                I received my Ph.D. in Photogrammetry and Remote Sensing from Wuhan University in 2023, advised by Prof.
                <a href="http://rsidea.whu.edu.cn/">Yanfei Zhong</a> and Prof. <a
                    href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html">Liangpei Zhang</a>.
                I obtained B.S. degree from the School of Geography and Information Engineering, China University of
                Geosciences, Wuhan, China, in 2018.
                <!--                I'm now a member of <a href="http://rsidea.whu.edu.cn/">RSIDEA group</a>, advised by Prof. <a-->
                <!--                    href="http://rsidea.whu.edu.cn/">Yanfei Zhong</a> and Prof. <a-->
                <!--                    href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html">Liangpei Zhang</a>.-->
            </p>
            <p>
                My research interest is in Earth Vision and Simulation, especially multi-modal and multi-temporal remote sensing image
                analysis.
                <br>
                My research goal is to design original and insightful GeoAI technologies to help solve societal and environmental challenges facing humanity, in pursuit of a sustainable future.
                Meanwhile, I am an enthusiast of remote sensing data science competitions (commonly used ID: EVER), but now I have little time to play these games :(
            </p>

            Our Change Family:
            <ul>
                <li><a href="https://www.sciencedirect.com/science/article/pii/S0924271624002624">Probabilistic Change Model (PCM)</a> (unified change modeling principle)</li>
                <li><a href="https://www.sciencedirect.com/science/article/pii/S0924271624002624">ChangeSparse</a> (an instance of Deep PCM with a powerful sparse change transformer for binary, o2m and m2m change detection tasks)</li>
                <li><a href="https://arxiv.org/abs/2108.07002">ChangeStar</a>, <a href="https://link.springer.com/article/10.1007/s11263-024-02141-4">ChangeStar2</a> (single-temporal change
                    representation learning, temporal symmetry)
                </li>
                <li><a href="https://www.sciencedirect.com/science/article/pii/S0034425721003564">ChangeOS</a> (one-to-many [o2m] semantic change detection
                    architecture, deep object-based change detection, building damage assessment)
                </li>
                <li><a href="https://www.sciencedirect.com/science/article/pii/S0034425724004425">STCA</a> (transferable building damage assessment, single-temporal change adaptation)</li>
                <li><a href="https://www.sciencedirect.com/science/article/pii/S0924271621002835">ChangeMask</a> (many-to-many [m2m] semantic change detection
                    architecture, temporal symmetric change representation)
                </li>
                <li><a href="https://arxiv.org/abs/2309.17031">Changen</a>, <a href="https://arxiv.org/abs/2406.17998">Changen2</a> (generative change modeling, the first multi-temporal remote sensing image-mask generator)</li>
                <li><a href="https://arxiv.org/abs/2402.01188">Segment Any Change</a> (the first zero-shot change detector)</li>
                <li><a href="https://github.com/Z-Zheng/pytorch-change-models">torchange</a> (a unified change representation learning benchmark library, open-source software)</li>
            </ul>


            <p>Email: zhuozheng [at] cs [dot] stanford [dot] edu; zhengzhuo [at] whu [dot] edu [dot] cn</p>
            <ul>
                <li class="link">
                    <a href="https://github.com/Z-Zheng">
                        <i class="fab fa-github"></i>
                        Github
                    </a>
                </li>
                <li class="link">
                    <a href="https://scholar.google.com/citations?user=CREpn_AAAAAJ&hl=zh-CN">
                        <i class="fab fa-google"></i>
                        Google Scholar
                    </a>
                </li>
                <li class="link">
                    <a href="https://www.researchgate.net/profile/Zhuo_Zheng7">
                        <i class="fab fa-researchgate"></i>
                        ResearchGate
                    </a>
                </li>
                <li class="link">
                    <a href="https://orcid.org/0000-0003-1811-6725">
                        <i class="fab fa-orcid"></i>
                        ORCID
                    </a>
                </li>
                <li class="link">
                    <a href="https://twitter.com/ZhuoZheng2">
                        <i class="fab fa-twitter-square"></i>
                        Twitter
                    </a>
                </li>
            </ul>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12" name="news">
            <h3>Recent News</h3>
            <p>2024.10, Changen2 got accepted to IEEE TPAMI.</p>
            <p>2024.10, Awarded with the 2024 Graduate Academic Innovation Outstanding Prize.</p>
            <p>2024.09, Segment Any Change got accepted to NeurIPS 2024.</p>
            <p>2024.09, selected for Stanford University's <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/7">World Top 2% Scientists List</a> (Geological & Geomatics Engineering) for 2024.</p>
            <p>2024.09, <a href="https://www.sciencedirect.com/science/article/pii/S0034425724004425">STCA</a> got accepted to RSE.</p>
            <p>2024.06, <a href="https://www.sciencedirect.com/science/article/pii/S0924271624002624">DPCM and ChangeSparse</a> got accepted to ISPRS P&RS.</p>
            <p>2024.05, <a href="https://link.springer.com/article/10.1007/s11263-024-02141-4">ChangeStar2</a> got accepted in IJCV.</p>
            <p>2023.10, <a href="https://zenodo.org/record/8404754">Urban Vehicle Segmentation (UV6K) dataset</a> is
                publicly available. Use it in your study now!</p>
            <p>2023.07, One paper is accepted by ICCV 2023.</p>
            <p>2023.07, One paper is accepted by IEEE TPAMI.</p>
            <p>2023.06, Awarded with Li Xiaowen Remote Sensing Young Scholar Award.</p>
<!--            <p>2022.12, Awarded with the 16th Wuhan University Top Ten Academic Stars.</p>-->
<!--            <p>2022.10, Awarded with the 2022 Graduate Academic Innovation Outstanding Prize.</p>-->
            <!--            <p>2021.12, Awarded with "Wang Zhizhuo Innovation Talent" Outstanding Prize.</p>-->
            <!--            <p>2021.10, One paper is accepted by NeurIPS 2021 Datasets and Benchmarks.</p>-->
            <!--            <p>2021.10, One paper is accepted by ISPRS P&RS.</p>-->
            <!--            <p>2021.08, One paper is accepted by RSE.</p>-->
            <!--            <p>2021.07, One paper is accepted by ICCV 2021.</p>-->
            <!--            <p>2021.07, I win the 5th place in the Overhead Geopose Challenge hosted by NGA.</p>-->
            <!--            <p>2021.03, Our team win the 4th place in 2021 IEEE GRSS Data Fusion Contest, Track: Multitemporal Semantic-->
            <!--                Change Detection.</p>-->
            <!--            <p>2021.03, Our <a href="https://www.ingentaconnect.com/content/asprs/pers/2020/00000086/00000003/art00006">PE&RS-->
            <!--                paper</a> wins the first place in the 2021 John I. Davidson President’s Award.-->
            <!--            <p>2020.12, One paper is accepted by ISPRS P&RS.</p>-->
            <!--            <p>2020.11, the <a href="https://github.com/Z-Zheng/FarSeg">source code</a> of FarSeg (CVPR 2020) has been-->
            <!--                available.</p>-->
            <!--            <p>2020.10, Awarded with the 2020 Graduate Academic Innovation Outstanding Prize.</p>-->
            <!--            <p>2020.06, I win the top graduate award at SpaceNet 6 & EarthVision workshop challenge at CVPR 2020.</p>-->
            <!--            <p>2020.05, the <a href="https://github.com/Z-Zheng/FreeNet">source code</a> of FPGA (TGRS 2020) has been-->
            <!--                available.</p>-->
            <!--            <p>2020.04, One paper is accepted by ISPRS P&RS.</p>-->
            <!--            <p>2020.03, One paper is accepted by TGRS.</p>-->
            <!--            <p>2020.02, One paper is accepted by CVPR 2020.</p>-->
            <!--            &lt;!&ndash;            <p>2020.02, I achieve 4th overall in <a href="https://xview2.org/">xView2 Challenge</a>.</p>&ndash;&gt;-->
            <!--            <p>2020.01, One paper is accepted by TGRS.</p>-->
        </div>
    </div>

    <!--    paper-->
    <div class="row">
        <div class="col-md-12">
            <h3>Selected Publication</h3>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <table class="table table-hover" style="border-collapse: separate">
                <tbody style="font-family: Arial,serif">
                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                Changen2: Multi-Temporal Remote Sensing Generative Change Foundation Model
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Stefano Ermon, Dongjun Kim, Liangpei Zhang, Yanfei Zhong</span>
                            <br>
                            IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2024
                            <br>
                            SCI Q1 Top
                            <br>
                            <span>
                                <a href="https://arxiv.org/abs/2406.17998"><span style="color: #808080">paper</span></a>&nbsp;&nbsp;&nbsp;
                                <b>
                                    <a href="https://github.com/Z-Zheng/pytorch-change-models">
                                        <span style="color: #FF0000">code (soon)</span>
                                    </a>
                                </b>&nbsp;&nbsp;&nbsp;
                                <b>
                                    <a href="https://github.com/Z-Zheng/pytorch-change-models">
                                        <span style="color: #FF0000">Changen2-S1-15k dataset</span>
                                    </a>
                                </b>&nbsp;&nbsp;&nbsp;
                                <b>
                                    <a href="https://github.com/Z-Zheng/pytorch-change-models">
                                        <span style="color: #FF0000">Changen2-S9-27k dataset</span>
                                    </a>
                                </b>
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b>
                                <b class="my_highlight">Generative Change Foundation Model</b>, Changen2 can be trained at scale using self-supervision, yielding change supervisory signals from unlabeled single-temporal images;
                               The resulting task-specific foundation model possesses inherent zero-shot change detection capabilities and excellent transferability.
                            </span>
                        </p>
                    </td>
                </tr>
                <tr>
                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>

                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                Segment Any Change
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Yanfei Zhong, Liangpei Zhang, Stefano Ermon</span>
                            <br>
                            38th Annual Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024
                            <br>
                            <span>
                                <a href="https://arxiv.org/abs/2402.01188"><span style="color: #808080">paper</span></a>&nbsp;&nbsp;&nbsp;
                                <b>
                                    <a href="https://github.com/Z-Zheng/pytorch-change-models">
                                        <span style="color: #FF0000">code</span>
                                    </a>
                                </b>
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b> <b class="my_highlight">Zero-shot Change Detection</b> is introduced for the first time; Training-free Adaptation for Foundation models.
                            </span>
                        </p>
                    </td>
                </tr>
                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>

                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                Towards transferable building damage assessment via unsupervised single-temporal change adaptation
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Yanfei Zhong, Liangpei Zhang, Marshall Burke, David B. Lobell, Stefano Ermon</span>
                            <br>
                            Remote Sensing of Environment (<b>RSE</b>), 2024
                            <br>
                            SCI Q1 Top, ranking it 1 out of 32 in Remote Sensing
                            <br>
                            <span>
                                <a href="https://www.sciencedirect.com/science/article/pii/S0034425724004425"><span style="color: #808080">paper</span></a>&nbsp;&nbsp;&nbsp;
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b> <b class="my_highlight">Transferable building damage assessment</b>; Unsupervised single-temporal change adaptation (STCA) enables models to achieve adaptation with only target pre-disaster images.
                            </span>
                        </p>
                    </td>
                </tr>
                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                Unifying Remote Sensing Change Detection via Deep Probabilistic Change Models: From Principles, Models to Applications
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Yanfei Zhong, Ji Zhao, Ailong Ma, Liangpei Zhang</span>
                            <br>
                            ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS P&RS</b>), 2024
                            <br>
                            SCI Q1 Top, ranking it 1 out of 50 in Geography, Physical
                            <br>
                            <span>
                                <a href="https://www.sciencedirect.com/science/article/pii/S0924271624002624"><span style="color: #808080">paper</span></a>&nbsp;&nbsp;&nbsp;
                                <b>
                                    <a href="https://github.com/Z-Zheng/pytorch-change-models">
                                        <span style="color: #FF0000">code</span>
                                    </a>
                                </b>
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b>
                                Unified probabilistic change modeling: <b class="my_highlight">Probabilistic Change Model (PCM)</b>; and strong model instance: <b class="my_highlight">ChangeSparse</b>.
                            </span>
                        </p>
                    </td>
                </tr>
                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                Single-Temporal Supervised Learning for Universal Remote Sensing Change Detection
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Ailong Ma, Liangpei Zhang, Yanfei Zhong</span>
                            <br>
                            International Journal of Computer Vision (<b>IJCV</b>), 2024
                            <br>
                            SCI Q1 Top
                            <br>
                            <span>
                                <a href="https://link.springer.com/article/10.1007/s11263-024-02141-4"><span style="color: #808080">paper</span></a>&nbsp;&nbsp;&nbsp;
                                <b>
                                    <a href="https://github.com/Z-Zheng/pytorch-change-models">
                                        <span style="color: #FF0000">code</span>
                                    </a>
                                </b>
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b>
                                <b class="my_highlight">ChangeStar2:</b>
                                STAR with Faster and More Stable Convergence;
                                Universal Remote Sensing Change Detection (object, semantic, class-agnostic, time-series change)
                            </span>
                        </p>
                    </td>
                </tr>
                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                Scalable Multi-Temporal Remote Sensing Change Data Generation via Simulating Stochastic
                                Change Process
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Shiqi Tian, Ailong Ma, Liangpei Zhang, Yanfei Zhong</span>
                            <br>
                            International Conference on Computer Vision (<b>ICCV</b>), 2023
                            <br>
                            <span>
                                <a href="https://arxiv.org/pdf/2309.17031"><span style="color: #808080">paper</span></a>&nbsp;&nbsp;&nbsp;
                                <b>
                                    <a href="https://github.com/Z-Zheng/Changen">
                                        <span style="color: #FF0000">code</span>
                                    </a>
                                </b>
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b> <b class="my_highlight">New direction</b>: Generative Change Modeling; <b
                                    class="my_highlight">Changen</b>, Change generator, enables object change generation with controllable object property and change event; Effective <b
                                    class="my_highlight">synthetic change data pre-training</b>.
                            </span>
                        </p>
                    </td>
                </tr>
                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                FarSeg++: Foreground-Aware Relation Network for Geospatial Object Segmentation in High
                                Spatial Resolution Remote Sensing Imagery
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Yanfei Zhong, Junjue Wang, Ailong Ma, Liangpei Zhang</span>
                            <br>
                            IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2023
                            <br>
                            SCI Q1 Top
                            <br>
                            <span>
                                <a href="https://ieeexplore.ieee.org/document/10188509"><span style="color: #808080">paper</span></a>&nbsp;&nbsp;&nbsp;
                                <b>
                                    <a href="https://github.com/Z-Zheng/FarSeg">
                                        <span style="color: #FF0000">code</span>
                                    </a>
                                </b>&nbsp;&nbsp;
                                <b>
                                    <a href="https://zenodo.org/record/8404754"><span
                                            style="color: #FF0000">UV6K dataset</span></a>
                                </b>
                            </span>
                            <br>
                        </p>
                    </td>
                </tr>
                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                ChangeMask: Deep Multi-task Encoder-Transformer-Decoder Architecture for Semantic Change
                                Detection
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Yanfei Zhong, Shiqi Tian, Ailong Ma, Liangpei Zhang</span>
                            <br>
                            ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS P&RS</b>), 2022
                            <br>
                            SCI Q1 Top, ranking it 1 out of 50 in Geography, Physical
                            <br>
                            <span>
                                <a href="https://www.sciencedirect.com/science/article/pii/S0924271621002835">
                                    <span style="color: #808080">paper</span></a>
                                &nbsp;&nbsp;&nbsp;
                                <b><a href="https://github.com/Z-Zheng/pytorch-change-models">
                                        <span style="color: #FF0000">code</span>
                                </a></b>
                                &nbsp;&nbsp;&nbsp;
                                <b>SECOND dataset:
                                    <a href="assets/changemask/SECOND/train.csv"><span
                                            style="color: #FF0000">train</span></a> /
                                    <a href="assets/changemask/SECOND/val.csv"><span
                                            style="color: #FF0000">val</span></a>
                                    split (ours)
                                </b>
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b> <b class="my_highlight">Disentangled semantic and change representation</b> and <b
                                    class="my_highlight">temporal symmetric transformer (TST)</b> for <b
                                    class="my_highlight">semantic change detection</b>.</span>
                            <br>
                            <span style="color: #FF0000"><b>ESI Highly Cited Paper</b></span>
                        </p>
                    </td>
                </tr>
                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                Building Damage Assessment for Rapid Disaster Response with a Deep Object-based Semantic
                                Change Detection Framework: from
                                natural disasters to man-made disasters
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Yanfei Zhong, Junjue Wang, Ailong Ma, Liangpei Zhang</span>
                            <br>
                            Remote Sensing of Environment (<b>RSE</b>), 2021
                            <br>
                            SCI Q1 Top, ranking it 1 out of 32 in Remote Sensing
                            <br>
                            <span>
                                <a href="https://www.sciencedirect.com/science/article/pii/S0034425721003564">
                                    <span style="color: #808080">paper</span></a>&nbsp;&nbsp;&nbsp;
                                <b><a href="https://github.com/Z-Zheng/ChangeOS">
                                    <span style="color: #FF0000">code</span>
                                </a></b>
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b> A <b class="my_highlight">deep object-based semantic change
                                    detection</b> method for <b class="my_highlight">building damage assessment</b> in the context of <b
                                    class="my_highlight">disaster response</b>.</span>
                            <br>
                            <span style="color: #FF0000"><b>ESI Highly Cited Paper</b></span>
                            <br>
                            <span class="fa fa-star checked"></span>
                            <b>Our solution is xView2 4th overall officially,
                                which is a unique single-model solution among top-5.
                            </b>
                        </p>
                    </td>
                </tr>
                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                Change is Everywhere: Single-Temporal Supervised Object Change Detection in
                                Remote Sensing Imagery
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Ailong Ma, Liangpei Zhang, Yanfei Zhong</span>
                            <br>
                            International Conference on Computer Vision (<b>ICCV</b>), 2021
                            <br>
                            <span>
                                    <a href="https://arxiv.org/abs/2108.07002">
                                        <span style="color: #808080">paper</span>
                                    </a>&nbsp;&nbsp;&nbsp;
                                    <a href="http://zhuozheng.top/changestar">
                                        <span style="color: #808080">project</span>
                                    </a>&nbsp;&nbsp;&nbsp;
                                    <b>
                                        <a href="https://github.com/Z-Zheng/ChangeStar">
                                            <span style="color: #FF0000">code</span>
                                        </a>
                                    </b>
                                </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b> A <b
                                    class="my_highlight">single-temporal supervised</b>
                                    learning algorithm and a plug-and-play change detection head: <b
                                        class="my_highlight">ChangeMixin</b> for <b class="my_highlight">change
                                        detection.</b></span>
                            <br>
                            <span class="fa fa-star checked">
                            </span>
                            <b>The method has been included in</b> <a
                                    href="https://github.com/microsoft/torchgeo">microsoft/torchgeo</a>
                                and <a href="https://github.com/PaddlePaddle/PaddleRS">PaddlePaddle/PaddleRS</a>.
                        </p>
                    </td>
                </tr>
                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                LoveDA: A Remote Sensing Land-Cover Dataset for Domain Adaptive Semantic Segmentation
                            </i>
                            <br>
                            <span style="color: #000000">Junjue Wang<sup>*</sup>, <b>Zhuo Zheng</b><sup>*</sup>, Ailong Ma, Xiaoyan Lu, Yanfei Zhong (* Equal contribution)</span>
                            <br>
                            35th Annual Conference on Neural Information Processing Systems (<b>NeurIPS</b> Datasets &
                            Benchmarks Track), 2021
                            <br>
                            <span>
                                    <a href="https://arxiv.org/abs/2110.08733">
                                        <span style="color: #808080">paper</span>
                                    </a>
                                    &nbsp;&nbsp;&nbsp;
                                    <b>
                                        <a href="https://github.com/Junjue-Wang/LoveDA">
                                            <span style="color: #FF0000">dataset/code</span>
                                        </a>
                                    </b>
                                </span>
                            <br>
                        </p>
                    </td>
                </tr>

                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                Deep Multisensor Learning for Missing-Modality All-Weather Mapping
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Ailong Ma, Liangpei Zhang, Yanfei Zhong</span>
                            <br>
                            ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS P&RS</b>), 2021
                            <br>
                            SCI Q1 Top, ranking it 1 out of 50 in Geography, Physical
                            <br>
                            <span>
                                    <a href="https://www.sciencedirect.com/science/article/pii/S0924271620303476">
                                        <span style="color: #808080">paper</span>
                                    </a>
                                </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b> A <b
                                    class="my_highlight">registration-free</b>
                        multi-modal/sensor learning algorithm via exploring <b class="my_highlight">meta-modal/sensory
                            representation</b> for <b class="my_highlight">all-weather mapping</b>.</span>
                        </p>
                    </td>
                </tr>

                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                Foreground-Aware Relation Network for Geospatial Object Segmentation in High
                                Spatial Resolution Remote Sensing Imagery
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Yanfei Zhong, Junjue Wang, Ailong Ma</span>
                            <br>
                            Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020
                            <br>
                            <span>
                                <a href="https://arxiv.org/pdf/2011.09766.pdf">
                                    <span style="color: #808080">paper</span>
                                </a>&nbsp;&nbsp;&nbsp;
                                <b>
                                    <a href="https://github.com/Z-Zheng/FarSeg">
                                        <span style="color: #FF0000">code</span>
                                    </a>
                                </b>
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b> <b
                                    class="my_highlight">Explicit foreground modeling</b>
                    from the perspectives of <b class="my_highlight">relation</b> and <b class="my_highlight">optimization</b>
                    for real-time geospatial object segmentation.</span>
                            <br>
                            <span class="fa fa-star checked"></span>
                            <span class="itemtitle"><b>The method has been included in</b> <a
                                    href="https://github.com/microsoft/torchgeo">microsoft/torchgeo</a>
                                and <a href="https://github.com/PaddlePaddle/PaddleRS">PaddlePaddle/PaddleRS</a>.
                            </span>
                        </p>
                    </td>
                </tr>

                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                FPGA: Fast Patch-Free Global Learning Framework for Fully End-to-End
                                Hyperspectral Image Classification
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Yanfei Zhong, Ailong Ma, Liangpei Zhang</span>
                            <br>
                            IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), 2020
                            <br>
                            SCI Q1 Top
                            <br>
                            <span>
                                <a href="https://ieeexplore.ieee.org/document/9007624">
                                    <span style="color: #808080">paper</span>
                                </a>&nbsp;&nbsp;&nbsp;
                                <b>
                                    <a href="https://github.com/Z-Zheng/FreeNet">
                                        <span style="color: #FF0000">code</span>
                                    </a>
                                </b>
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b> <b class="my_highlight">Patch-free is all you need</b>
                    towards faster and stronger hyperspectral image classification.</span>
                            <br>
                            <span class="fa fa-star checked"></span>
                            <span class="itemtitle"><b>The method has been included in</b> <a
                                    href="https://github.com/WHULuoJiaTeam/luojianet">WHULuoJiaTeam/luojianet</a>.
                            </span>
                            <br>
                            <span style="color: #FF0000"><b>ESI Highly Cited Paper</b></span>
                        </p>
                    </td>
                </tr>

                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                HyNet: Hyper-scale object detection network framework for multiple spatial
                                resolution remote sensing imagery
                            </i>
                            <br>
                            <span style="color: #000000"><b>Zhuo Zheng</b>, Yanfei Zhong, Ailong Ma, Xiaobing Han, Ji Zhao, Yanfei Liu,
                Liangpei Zhang</span>
                            <br>
                            ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS P&RS</b>), 2020
                            <br>
                            SCI Q1 Top, ranking it 1 out of 50 in Geography, Physical
                            <br>
                            <span>
                                <a href="https://www.sciencedirect.com/science/article/pii/S0924271620301167">
                                    <span style="color: #808080">paper</span>
                                </a>
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b> <b class="my_highlight">Hyper-scale = Multi-scale &times;
                    Multi-scale</b>, a new perspective of scale modeling at the convolutional groups. </span>
                        </p>
                    </td>
                </tr>

                <tr>
                    <td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="12">
                        &nbsp;
                    </td>
                    <td style="border-style: none; border-width: medium;">
                        <p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;">
                            <i style="font-size: 15px">
                                COLOR: Cycling, Offline Learning, and Online Representation Framework for
                                Airport and Airplane Detection Using GF-2 Satellite Images
                            </i>
                            <br>
                            <span style="color: #000000">Yanfei Zhong, <b>Zhuo Zheng<sup>*</sup></b>, Ailong Ma, Xiaoyan Lu, Liangpei Zhang &nbsp (* denotes the corresponding author)</span>
                            <br>
                            IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), 2020
                            <br>
                            SCI Q1 Top
                            <br>
                            <span>
                                <a href="https://ieeexplore.ieee.org/document/9091107">
                                    <span style="color: #808080">paper</span>
                                </a>
                            </span>
                            <br>
                            <span class="paper_highlight"><b>Highlight:</b> <b
                                    class="my_highlight">Evolvable model and dataset</b>:
                    making your model and dataset both great again for new domain data.</span>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <h3>Teaching</h3>
            <div class="alert alert-dismissible">
                <ul>
                    <li><b class="itemtitle">Fall 2023/2024: Data for Sustainable Development (CS 325B)</b></li>
                </ul>
            </div>
        </div>
    </div>
    <!--    award-->
    <div class="row">
        <div class="col-md-12">
            <h3>Honors and Awards</h3>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <div class="alert alert-dismissible alert-danger">
                <b class="itemtitle">2024 Graduate Academic Innovation Outstanding Prize, Wuhan
                    University&nbsp(武汉大学“研究生学术创新奖”<b class="my_highlight">&nbsp特等奖&nbsp(研究生学术创新校长奖)</b>)</b><br>
                <a href="https://gs.whu.edu.cn/content.jsp?urltype=news.NewsContentUrl&wbtreeid=1063&wbnewsid=101421">announcement</a>
            </div>
            <div class="alert alert-dismissible alert-danger">
                <b class="itemtitle">2023 Li Xiaowen Remote Sensing Young Scholar Award
                    &nbsp(李小文遥感科学青年奖)</b><br>
                <a href="https://geo.bnu.edu.cn/xwzx/9ddb15a97da84d3aaf1d4d251b247f13.html">press</a>
            </div>
            <div class="alert alert-dismissible alert-danger">
                <b class="itemtitle">16th Wuhan University Top Ten Academic Stars
                    &nbsp(武汉大学第十六届研究生“十大学术之星”)</b><br>
                <a href="https://ygb.whu.edu.cn/info/1086/20257.htm">announcement</a>
            </div>
            <div class="alert alert-dismissible alert-danger">
                <b class="itemtitle">2022 Graduate Academic Innovation Outstanding Prize, Wuhan
                    University&nbsp(武汉大学“研究生学术创新奖”<b class="my_highlight">&nbsp特等奖&nbsp(研究生学术创新校长奖)
                        & “研究生英诺卓越奖学金”</b>)</b><br>
                <a href="https://gs.whu.edu.cn/content.jsp?urltype=news.NewsContentUrl&wbtreeid=1057&wbnewsid=9971">announcement</a>
            </div>
            <div class="alert alert-dismissible alert-danger">
                <b class="itemtitle">2020-2021 "Wang Zhizhuo Innovation Talent" Outstanding Prize &nbsp("王之卓创新人才奖"<b
                        class="my_highlight">&nbsp特等奖</b>)</b><br>
                <a href="http://rsgis.whu.edu.cn/info/1080/9862.htm">announcement</a>
            </div>
            <div class="alert alert-dismissible alert-info">
                <b class="itemtitle">2021 National Scholarship for Graduate Student &nbsp(博士研究生国家奖学金)</b><br>
                <a href="https://www.whu.edu.cn/info/1118/19369.htm">announcement</a>
            </div>
            <div class="alert alert-dismissible alert-warning">
                <b class="itemtitle">Overhead Geopose Challenge, <b class="my_highlight">5th Place (5/444)</b></b><br>
                <small>This challenge is hosted by the National Geospatial-Intelligence Agency (NGA)</small><br>
                <b class="myname">Zhuo Zheng</b> (id: chuchu in the leaderboard)<br>
                <a href="https://www.drivendata.org/competitions/78/overhead-geopose-challenge/">website</a><br>
            </div>
            <div class="alert alert-dismissible alert-warning">
                <b class="itemtitle">2021 IEEE GRSS Data Fusion Contest, Track: Multitemporal Semantic Change Detection,
                    <b
                            class="my_highlight">4th Place</b></b><br>
                <b class="myname">Zhuo Zheng</b>, Junjue Wang, Yinhe Liu, Shiqi Tian, Yanfei Zhong, Ailong Ma<br>
                <a href="https://www.grss-ieee.org/community/technical-committees/2021-ieee-grss-data-fusion-contest-track-msd/">website</a>
                &nbsp
                <a href="https://www.grss-ieee.org/community/technical-committees/2021-ieee-grss-data-fusion-contest-results/">announcement</a>
            </div>
            <div class="alert alert-dismissible alert-info">
                <b class="itemtitle">2021 John I. Davidson President’s Award<b
                        class="my_highlight">, 1st Place</b></b><br>
                <a href="https://www.asprs.org/awards-and-scholarships/award-winners/2021-award-winners.html">announcement</a>
            </div>
            <div class="alert alert-dismissible alert-danger">
                <b class="itemtitle">2020 Graduate Academic Innovation Outstanding Prize, Wuhan
                    University&nbsp(武汉大学“研究生学术创新奖”<b
                            class="my_highlight">&nbsp特等奖&nbsp(研究生学术创新校长奖)</b>)</b><br>
                <a href="https://gs.whu.edu.cn/info/1057/7261.htm">announcement</a>
            </div>
            <div class="alert alert-dismissible alert-warning">
                <b class="itemtitle">SpaceNet 6 & EarthVision workshop challenge at CVPR 2020, <b
                        class="my_highlight">Top Graduate Award</b></b><br>
                <b class="myname">Zhuo Zheng</b>, Junjue Wang, Dingyuan Chen (Team name: __EVER__ in Topcoder)<br>
                <a href="https://spacenet.ai/sn6-challenge/">website</a>
                &nbsp
                <a href="https://medium.com/the-downlinq/spacenet-6-announcing-the-winners-df817712b515">announcement</a>
            </div>
            <div class="alert alert-dismissible alert-warning">
                <b class="itemtitle">xView2 Challenge, <b class="my_highlight">4th Place (4/3500+), overall</b></b><br>
                <b class="myname">Zhuo Zheng</b>, Junjue Wang, Yanfei Zhong, Ailong Ma, Liangpei Zhang<br>
                <a href="https://xview2.org/challenge">website</a>
                &nbsp
                <a href="https://github.com/DIUx-xView/xView2_fourth_place">code</a>
            </div>
            <div class="alert alert-dismissible alert-warning">
                <b class="itemtitle">2019 IEEE GRSS Data Fusion Contest, Single-view Semantic 3D Challenge, <b
                        class="my_highlight">2nd
                    Place</b></b><br>
                <b class="myname">Zhuo Zheng</b>, Yanfei Zhong, Junjue Wang<br>
                <a href="http://www.grss-ieee.org/community/technical-committees/data-fusion/2019-ieee-grss-data-fusion-contest-results/">website</a>
                &nbsp
                <a href="https://ieeexplore.ieee.org/abstract/document/8897927">tech report</a>
            </div>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <h3>Invited Talks</h3>
            <div class="alert alert-dismissible alert-dark">
                <ul>
                    <li>
                        <b class="itemtitle">Scalable Multi-Temporal Remote Sensing Change Data Generation via Simulating
                            Stochastic
                            Change Process</b><br>
                        <h6>University of Georgia (UGA) GeoAI Talk Series I, 2024.02.29</h6>
                    </li>
                    <li>
                        <b class="itemtitle">Change is Everywhere: Single-Temporal Supervised Object Change Detection in
                            Remote Sensing Imagery</b><br>
                        <h6>IEEE Geoscience and Remote Sensing Society (GRSS) Wuhan Student Chapter, 2023.02.24</h6>
                    </li>
                    <li>
                        <b class="itemtitle">变化无处不在：单时相监督的遥感影像变化检测</b><br>
                        <h6>中国图象图形学学会(CSIG) 第一期学生会员分享论坛, 2022.12.23</h6>
                    </li>
                    <li>
                        <b class="itemtitle">Building Damage Assessment with Deep Object-based Semantic Change Detection
                            Framework:
                            From natural disasters to man-made disasters</b><br>
                        <b class="my_highlight">Excellent Presentation Award</b>
                        <h6>The 2021 International Graduate Workshop on GeoInformatics (IGWG2021), 2021.12.18</h6>
                    </li>
                    <li>
                        <b class="itemtitle">面向地理目标的遥感视觉理解</b><br>
                        <h6>武汉大学, GeoScience Cafe #281, 2020.11.27</h6>
                    </li>
                    <li>
                        <b class="itemtitle">WE1.R7.3: Pop-Net: Encoder-Dual Decoder for Semantic Segmentation and
                            Single-View Height Estimation</b><br>
                        <h6>2019 IEEE Geoscience and Remote Sensing Symposium (IGARSS), IEEE GRSS Data Fusion Contest I,
                            2019.07.31</h6>
                    </li>
                </ul>
            </div>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <h3>Academic Service</h3>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <div class="alert alert-dismissible alert-dark">
                <h5><b>Journal Reviewer</b></h5>
                <ul>
                    <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
                    <li>International Journal of Computer Vision (IJCV)</li>
                    <li>Remote Sensing of Environment (RSE)</li>
                    <li>ISPRS Journal of Photogrammetry and Remote Sensing (ISPRS P&RS)</li>
                    <li>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</li>
                    <li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
                    <li>IEEE Transactions on Cybernetics (TCYB)</li>
                    <li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
                    <li>IEEE Geoscience and Remote Sensing Letters (GRSL)</li>
                    <li>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (JSTARS)</li>
                    <li>International Journal of Applied Earth Observation and Geoinformation (JAG)</li>
                    <li>International Journal of Remote Sensing (IJRS)</li>
                </ul>
                <h5><b>Conference Reviewer</b></h5>
                <ul>
                    <li>ICML 2024</li>
                    <li>ICLR 2024-2025</li>
                    <li>ICCV 2023</li>
                    <li>ECCV 2022-2024</li>
                    <li>CVPR 2022-2024</li>
                    <li>NeurIPS 2021, 2023, 2024</li>
                </ul>
                <h5><b>Program Committee</b></h5>
                <ul>
                    <a href="https://www.mair2.com/organizers#h.9nganr5c5yfr">
                        <li>Multi-Agent Interaction and Relational Reasoning Workshop, ICCV 2021</li>
                    </a>
                </ul>
            </div>
        </div>
    </div>


</div>
<div style="text-align: center">
    <a href="https://www.easycounter.com/">
        <img src="https://www.easycounter.com/counter.php?zhuozheng"
             border="0" alt="Web Counter"></a>
    unique visitors,
    <a href="https://www.easycounter.com/">
        <img src="https://www.easycounter.com/counter.php?zhuozhengx"
             border="0" alt="HTML Hit Counter"></a>
    page views since March 2020
    <br>
</div>


</body>

</html>